import os
import gradio as gr
from dotenv import load_dotenv
from tianji.knowledges.langchain_onlinellm.models import ZhipuAIEmbeddings, ZhipuLLM
from langchain_chroma import Chroma
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain import hub
from tianji import TIANJI_PATH
from huggingface_hub import snapshot_download
import argparse

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
parser = argparse.ArgumentParser(description='Launch Gradio RAG application')
parser.add_argument('--local-only', action='store_true', help='Only allow localhost access (127.0.0.1)')
parser.add_argument('--port', type=int, default=7860, help='The port the server should listen on (default: 7860)')
parser.add_argument('--root_path', type=str, default=None, help='The root path of the server')
args = parser.parse_args()

# ä½¿ç”¨ Hugging Face çš„ huggingface_hub ä¸‹è½½æ•°æ®é›†
destination_folder = os.path.join(TIANJI_PATH, "temp", "tianji-chinese")
if not os.path.exists(destination_folder):
    snapshot_download(
        repo_id="sanbu/tianji-chinese",
        local_dir=destination_folder,
        repo_type="dataset",
    )


def create_vectordb(
    data_path: str,
    persist_directory: str,
    embedding_func,
    chunk_size: int,
    force: bool = False,
):
    if os.path.exists(persist_directory) and not force:
        return Chroma(
            persist_directory=persist_directory, embedding_function=embedding_func
        )

    if force and os.path.exists(persist_directory):
        if os.path.isdir(persist_directory):
            import shutil

            shutil.rmtree(persist_directory)
        else:
            os.remove(persist_directory)

    # ä½¿ç”¨ UTF-8 ç¼–ç åŠ è½½æ–‡ä»¶ï¼Œé¿å… Windows ç³»ç»Ÿä¸Šçš„ç¼–ç é—®é¢˜
    loader = DirectoryLoader(
        data_path, 
        glob="*.txt", 
        loader_cls=TextLoader,
        loader_kwargs={"encoding": "utf-8"}
    )
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size, chunk_overlap=200
    )
    split_docs = text_splitter.split_documents(loader.load())
    if len(split_docs) == 0:
        raise gr.Error("å½“å‰çŸ¥è¯†æ•°æ®æ— æ•ˆ,å¤„ç†æ•°æ®åä¸ºç©º")

    vector_db = Chroma.from_documents(
        documents=split_docs,
        embedding=embedding_func,
        persist_directory=persist_directory,
    )
    return vector_db


def initialize_chain(chunk_size: int, persist_directory: str, data_path: str):
    print("åˆå§‹åŒ–æ•°æ®åº“å¼€å§‹")
    embeddings = ZhipuAIEmbeddings()
    vectordb = create_vectordb(data_path, persist_directory, embeddings, chunk_size)
    retriever = vectordb.as_retriever()
    prompt = hub.pull("rlm/rag-prompt")
    prompt.messages[
        0
    ].prompt.template = """
    æ‚¨æ˜¯ä¸€åç”¨äºé—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœæ‚¨ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±ç›´æ¥è¯´ä¸çŸ¥é“ã€‚\
    1.æ ¹æ®æˆ‘çš„æé—®,æ€»ç»“æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸­ä¸æé—®æœ€æ¥è¿‘çš„éƒ¨åˆ†,å°†ç›¸å…³éƒ¨åˆ†æµ“ç¼©ä¸ºä¸€æ®µè¯è¿”å›;
    2.æ ¹æ®è¯­æ–™ç»“åˆæˆ‘çš„é—®é¢˜,ç»™å‡ºå»ºè®®å’Œè§£é‡Šã€‚\
    \né—®é¢˜ï¼š{question} \nä¸Šä¸‹æ–‡ï¼š{context} \nç­”æ¡ˆï¼š
    """
    llm = ZhipuLLM()
    print("åˆå§‹åŒ–æ•°æ®åº“ç»“æŸ")
    return (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


def handle_question(chain, question: str, chat_history):
    if not question:
        return "", chat_history
    if chat_history is None:
        chat_history = []
    try:
        result = chain.invoke(question)
        # ä½¿ç”¨å­—å…¸æ ¼å¼å…¼å®¹æ–°ç‰ˆæœ¬ Gradio
        chat_history.append({"role": "user", "content": question})
        chat_history.append({"role": "assistant", "content": result})
        return "", chat_history
    except Exception as e:
        error_msg = str(e)
        chat_history.append({"role": "user", "content": question})
        chat_history.append({"role": "assistant", "content": f"é”™è¯¯: {error_msg}"})
        return "", chat_history


# ç¡®ä¿æ•°æ®å­˜åœ¨
data_path = os.path.join(TIANJI_PATH, "temp", "tianji-chinese", "RAG", "1-etiquette")
if not os.path.exists(data_path):
    raise FileNotFoundError(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")

# åˆå§‹åŒ–æ•°æ®åº“
chunk_size = 1024
persist_directory = os.path.join(TIANJI_PATH, "temp", "chromadb_1-etiquette")
model_chain = initialize_chain(chunk_size, persist_directory, data_path)

# åˆ›å»ºGradioç•Œé¢

TITLE = """
# Tianji äººæƒ…ä¸–æ•…å¤§æ¨¡å‹ç³»ç»Ÿ-æ•¬é…’ç‰ˆ(åŸºäºçŸ¥è¯†åº“å®ç°) æ¬¢è¿starï¼\n
## ğŸ¤–å¼€æºé¡¹ç›®åœ°å€ï¼šhttps://github.com/SocialAI-tianji/Tianji
## ä½¿ç”¨æ–¹æ³•ï¼šè¾“å…¥æç¤º,æˆ–ç‚¹å‡»Exampleè‡ªåŠ¨å¡«å……
## å¦‚æœè§‰å¾—å›ç­”ä¸æ»¡æ„,å¯ä»¥é‡å¤å¤šæ¬¡è¯¢é—®
### æˆ‘ä»¬çš„æ„¿æ™¯æ˜¯æ„å»ºä¸€ä¸ªä»æ•°æ®æ”¶é›†å¼€å§‹çš„å¤§æ¨¡å‹å…¨æ ˆå‚ç›´é¢†åŸŸå¼€æºå®è·µ.
"""

with gr.Blocks() as demo:
    gr.Markdown(TITLE)

    init_status = gr.Textbox(label="åˆå§‹åŒ–çŠ¶æ€", value="æ•°æ®åº“å·²åˆå§‹åŒ–", interactive=False)
    chatbot = gr.Chatbot(height=450, value=[])
    msg = gr.Textbox(label="è¾“å…¥ä½ çš„ç–‘é—®")

    examples = gr.Examples(
        label="å¿«é€Ÿç¤ºä¾‹",
        examples=[
            "å–é…’åº§ä½æ€ä¹ˆæ’",
            "å–é…’çš„å®Œæ•´æµç¨‹æ˜¯ä»€ä¹ˆ",
            "æ¨èçš„æ•¬é…’è¯æ€ä¹ˆè¯´",
            "å®´ä¼šæ€ä¹ˆç‚¹èœ",
            "å–é…’å®¹æ˜“é†‰æ€ä¹ˆåŠ",
            "å–é…’çš„è§„çŸ©æ˜¯ä»€ä¹ˆ",
        ],
        inputs=[msg],
    )

    with gr.Row():
        chat_button = gr.Button("èŠå¤©")
        clear_button = gr.ClearButton(components=[chatbot], value="æ¸…é™¤èŠå¤©è®°å½•")

    # Define a function to invoke the chain
    def invoke_chain(question, chat_history):
        return handle_question(model_chain, question, chat_history)

    chat_button.click(
        invoke_chain,
        inputs=[msg, chatbot],
        outputs=[msg, chatbot],
    )

# å¯åŠ¨Gradioåº”ç”¨
if __name__ == "__main__":
    # é»˜è®¤ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£ï¼Œå…è®¸å±€åŸŸç½‘å†…å…¶ä»–è®¾å¤‡è®¿é—®
    if args.local_only:
        server_name = '127.0.0.1'  # ä»…æœ¬åœ°è®¿é—®
    else:
        server_name = '0.0.0.0'  # å…è®¸å¤–éƒ¨è®¿é—®ï¼ˆé»˜è®¤ï¼‰
    
    server_port = args.port
    
    print(f"ğŸš€ å¯åŠ¨æœåŠ¡å™¨: http://{server_name}:{server_port}")
    if server_name == '0.0.0.0':
        print("ğŸ“± å±€åŸŸç½‘å†…å…¶ä»–è®¾å¤‡å¯é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®:")
        print(f"   http://<ä½ çš„IPåœ°å€>:{server_port}")
        print("   æç¤º: åœ¨å‘½ä»¤è¡Œè¿è¡Œ 'ipconfig' (Windows) æˆ– 'ifconfig' (Linux/Mac) æŸ¥çœ‹ä½ çš„IPåœ°å€")
    
    demo.launch(
        server_name=server_name,
        server_port=server_port,
        root_path=args.root_path
    )
